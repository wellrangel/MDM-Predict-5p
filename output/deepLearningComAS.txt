
Starting H2O JVM and connecting: .. Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         3 seconds 556 milliseconds 
    H2O cluster version:        3.10.4.6 
    H2O cluster version age:    2 months and 7 days  
    H2O cluster name:           H2O_started_from_R_wellrangel_cqp686 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   0.89 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  4 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    R Version:                  R version 3.3.3 (2017-03-06) 


> options(scipen=20)

> #h2o.set.seed(1234);
> #nao ler toda hora
> if (!file.exists("dadosOriginalCSV")) {
+   dadosOriginalCSV <- readData();
+   
+ }

> treino <- getTreinoData(dadosOriginalCSV)

> validacao <- getValidacaoData(dadosOriginalCSV)

> teste <- getTesteData(dadosOriginalCSV)

> treino.hex  <- as.h2o(treino) # convertendo df para formato h2o
  |=======================================================================================================| 100%

> validacao.hex  <- as.h2o(validacao) 
  |=======================================================================================================| 100%

> teste.hex  <- as.h2o(teste) 
  |=======================================================================================================| 100%

> x <- setdiff(names(dadosOriginalCSV), c(dadosOriginalCSV,"posicao", "minutos_partida", "idade","pontos_time_casa","pontos_time_fora", "id_jogador"," ..." ... [TRUNCATED] 

> y <- "posicao"

> #"ts_per", "eFG_per","ASTPer", "TurPer", "FTPer", "FG_per", "PirPer", 
> hyper_parametersDP <- list(
+   hidden=list(c(32,32,32),c(64,64)),
+   inpu .... [TRUNCATED] 

> #set search criteria
> search_criteria <- list(strategy = "RandomDiscrete", max_models=400)

> gridDL <- h2o.grid("deeplearning", 
+                    grid_id="dl_grid_test", 
+                    x=x, 
+                    y=y, 
+            .... [TRUNCATED] 
  |=======================================================================================================| 100%

> dl_sorted_grid <- h2o.getGrid(grid_id = "dl_grid_test", sort_by = "accuracy", decreasing = TRUE)

> print(dl_sorted_grid, exact_quantiles=TRUE)
<S4 Type Object>
attr(,"grid_id")
[1] "dl_grid_test"
attr(,"model_ids")
attr(,"model_ids")[[1]]
[1] "dl_grid_test_model_4"

attr(,"model_ids")[[2]]
[1] "dl_grid_test_model_1"

attr(,"model_ids")[[3]]
[1] "dl_grid_test_model_3"

attr(,"model_ids")[[4]]
[1] "dl_grid_test_model_2"

attr(,"model_ids")[[5]]
[1] "dl_grid_test_model_0"

attr(,"model_ids")[[6]]
[1] "dl_grid_test_model_7"

attr(,"model_ids")[[7]]
[1] "dl_grid_test_model_5"

attr(,"model_ids")[[8]]
[1] "dl_grid_test_model_6"

attr(,"hyper_names")
attr(,"hyper_names")[[1]]
[1] "hidden"

attr(,"hyper_names")[[2]]
[1] "input_dropout_ratio"

attr(,"hyper_names")[[3]]
[1] "rate"

attr(,"failed_params")
list()
attr(,"failure_details")
list()
attr(,"failure_stack_traces")
list()
attr(,"failed_raw_params")
<0 x 0 matrix>
attr(,"summary_table")
Hyper-Parameter Search Summary: ordered by decreasing accuracy
        hidden input_dropout_ratio rate            model_ids           accuracy
1     [64, 64]                0.05 0.02 dl_grid_test_model_4  0.699468085106383
2     [64, 64]                 0.0 0.02 dl_grid_test_model_1  0.699468085106383
3     [64, 64]                0.05 0.01 dl_grid_test_model_3  0.699468085106383
4     [64, 64]                 0.0 0.01 dl_grid_test_model_2  0.699468085106383
5 [32, 32, 32]                0.05 0.02 dl_grid_test_model_0             0.6875
6 [32, 32, 32]                0.05 0.01 dl_grid_test_model_7             0.6875
7 [32, 32, 32]                 0.0 0.02 dl_grid_test_model_5 0.6835106382978724
8 [32, 32, 32]                 0.0 0.01 dl_grid_test_model_6 0.6835106382978724
attr(,"class")
[1] "H2OGrid"
attr(,"class")attr(,"package")
[1] "h2o"

> # Grab the model_id based in AUC
> best_dl_model_id <- gridDL@model_ids[[1]]

> # The best model
> best_dl <- h2o.getModel(best_dl_model_id)

> print(h2o.performance(best_dl, valid=T))
H2OMultinomialMetrics: deeplearning
** Reported on validation data. **
** Metrics reported on full validation frame **

Validation Set Metrics: 
=====================

Extract validation frame with `h2o.getFrame("validacao")`
MSE: (Extract with `h2o.mse`) 0.2565942
RMSE: (Extract with `h2o.rmse`) 0.5065512
Logloss: (Extract with `h2o.logloss`) 0.8644078
Mean Per-Class Error: 0.3627413
Confusion Matrix: Extract with `h2o.confusionMatrix(<model>,valid = TRUE)`)
=========================================================================
Confusion Matrix: vertical: actual; across: predicted
           Ala AlaArmador AlaPivo Armador Pivo  Error       Rate
Ala         21          5       6       2    2 0.4167 =  15 / 36
AlaArmador   4          6       0       6    0 0.6250 =  10 / 16
AlaPivo      6          0      13       0    5 0.4583 =  11 / 24
Armador      2          3       0      23    0 0.1786 =   5 / 28
Pivo         1          0       4       0   32 0.1351 =   5 / 37
Totals      34         14      23      31   39 0.3262 = 46 / 141

Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>,valid = TRUE)`
=======================================================================
Top-5 Hit Ratios: 
  k hit_ratio
1 1  0.673759
2 2  0.886525
3 3  0.971631
4 4  0.985816
5 5  1.000000


> my_varimpDL <- h2o.varimp(best_dl)

> barplot(my_varimpDL$scaled_importance,
+         names.arg = my_varimpDL$variable,
+         space = 1,
+         las = 2,
+         main = "Variabl ..." ... [TRUNCATED] 

> model = best_dl

> # Summary of the best model
> pred2 = h2o.predict(object = model, newdata = teste.hex)
  |=======================================================================================================| 100%

> dataset_pred <- as.data.frame(pred2)

> sub_reg <- data.frame(id_jogador = teste$id_jogador,  id_partida = teste$id_partida, temporada = teste$nome_temporada, posicao =  dataset_pred$predi .... [TRUNCATED] 

> final <- cbind(dataset_pred, teste ) 

> #erro =  sqldf( "select * from final where predict != posicao")
> 
> perf <- h2o.performance(model, teste.hex)

> h2o.confusionMatrix(perf)
Confusion Matrix: vertical: actual; across: predicted
           Ala AlaArmador AlaPivo Armador Pivo  Error       Rate
Ala         25          4       4       2    0 0.2857 =  10 / 35
AlaArmador   4          6       0       2    1 0.5385 =   7 / 13
AlaPivo      6          0      11       0    4 0.4762 =  10 / 21
Armador      2          1       1      21    0 0.1600 =   4 / 25
Pivo         0          0      10       0   17 0.3704 =  10 / 27
Totals      37         11      26      25   22 0.3388 = 41 / 121

> mean(pred2$predict==teste.hex$posicao)
[1] 0.661157

> #h2o.shutdown(prompt=FALSE)