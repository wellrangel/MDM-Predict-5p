{
    "collab_server" : "",
    "contents" : "#Name of algorithm to use in grid search (gbm, randomForest, kmeans, glm, deeplearning, naivebayes, pca).\n#0.6744186\n#0.7209302 sem variaveis avancadas\n#0.7325581 sem parametros\n#0.7906977 com search\n#0.7906977 com hyper parametros\n#0.7906977 com 10 a 50 arvores\n#0.7906977 com 10 fold\n#0.7093023 com variaveis avancadas\n#0.744186 100 folds\nlibrary(h2o)\nlibrary(ggplot2)\nlibrary(sqldf)\n\n\nGBM<-function(h2o, treino.hex, validacao.hex, teste.hex, x, y)\n{\n  \n\nhyper_parametersGM = list( \n  ## restrict the search to the range of max_depth established above\n  #max_depth = seq(minDepth,maxDepth,1),         \n  \n  \n  ## more trees is better if the learning rate is small enough\n  ## use \"more than enough\" trees - we have early stopping\n  ntrees = c(10,50),\n  \n  ## search a large space of row sampling rates per tree\n  sample_rate = seq(0.2,1,0.01),                                             \n  \n  ## search a large space of column sampling rates per split\n  col_sample_rate = seq(0.2,1,0.01),                                         \n  \n  ## search a large space of column sampling rates per tree\n  col_sample_rate_per_tree = seq(0.2,1,0.01),                                \n  \n  ## search a large space of how column sampling per split should change as a function of the depth of the split\n  col_sample_rate_change_per_level = seq(0.9,1.1,0.01),                      \n  \n  ## search a large space of the number of min rows in a terminal node\n  min_rows = 2^seq(0,log2(nrow(treino))-1,1),                                 \n  \n  ## search a large space of the number of bins for split-finding for continuous and integer columns\n  nbins = 2^seq(4,10,1),                                                     \n  \n  ## search a large space of the number of bins for split-finding for categorical columns\n  nbins_cats = 2^seq(4,12,1),                                                \n  \n  ## search a few minimum required relative error improvement thresholds for a split to happen\n   min_split_improvement = c(0,1e-8,1e-6,1e-4),                               \n  \n  ## try all histogram types (QuantilesGlobal and RoundRobin are good for numeric columns with outliers)\n  histogram_type = c(\"UniformAdaptive\",\"QuantilesGlobal\",\"RoundRobin\")       \n)\n\nsearch_criteriaGM = list(\n  ## Random grid search\n  strategy = \"RandomDiscrete\",      \n  \n  ## limit the runtime to 60 minutes\n  max_runtime_secs = 3600,         \n  \n  ## build no more than 100 models\n  max_models = 100,                  \n  \n  ## random number generator seed to make sampling of parameter combinations reproducible\n  seed = 1234,                        \n  \n  ## early stopping once the leaderboard of the top 5 models is converged to 0.1% relative difference\n  stopping_rounds = 5,                \n  stopping_metric = \"AUTO\",\n  stopping_tolerance = 1e-3\n)\n\ngrid <- h2o.grid(\n  ## hyper parameters\n  hyper_params = hyper_parametersGM,\n  \n  ## hyper-parameter search configuration (see above)\n  search_criteria = search_criteriaGM,\n  \n  ## which algorithm to run\n  algorithm = \"gbm\",\n  \n  ## identifier for the grid, to later retrieve it\n  grid_id=\"gbm_grid_test\", \n  \n  ## standard model parameters\n  x=x, \n  y=y, \n  training_frame=treino.hex, \n  validation_frame=validacao.hex,\n  nfolds = 100,\n                                                          \n                                                           \n  \n  ## learning rate annealing: learning_rate shrinks by 1% after every tree \n  ## (use 1.00 to disable, but then lower the learning_rate)\n  \n  #learn_rate_annealing = 0.99,                                               \n  \n  ## early stopping based on timeout (no model should take more than 1 hour - modify as needed)\n  #max_runtime_secs = 3600,                                                 \n  \n  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n  #stopping_rounds = 5, stopping_tolerance = 1e-4,\n  \n  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n  #score_tree_interval = 10,                                                \n  \n  ## base random number generator seed for each model (automatically gets incremented internally for each model)\n  seed = 1234                                                             \n)\n\n\n## Sort the grid models by AUC\nsortedGrid <- h2o.getGrid(\"gbm_grid_test\", sort_by = \"accuracy\", decreasing = TRUE)    \nsortedGrid\n\n\nglm_sorted_grid <- h2o.getGrid(grid_id = \"gbm_grid_test\", sort_by = \"accuracy\", decreasing = TRUE)\n\nprint(glm_sorted_grid)\n\n#grid_models <- lapply(grid@model_ids, function(mid) {\n#  model = h2o.getModel(mid)\n#})\n\n\n# Grab the model_id based in AUC\nbest_glm_model_id <- grid@model_ids[[1]]\n\n# The best model\nbest_glm <- h2o.getModel(best_glm_model_id)\n\n\n\n\nscoring_history <- as.data.frame(best_glm@model$scoring_history)\nplot(scoring_history$number_of_trees, scoring_history$training_MSE, type=\"p\") #training mse\n\n## get the actual number of trees\nntrees <- best_glm@model$model_summary$number_of_trees\nprint(ntrees)\n\n \n\nmy_varimpGM <- h2o.varimp(best_glm)\nbarplot(my_varimpGM$scaled_importance,\n        names.arg = my_varimpGM$variable,\n        space = 1,\n        las = 2,\n        main = \"Variable Importance: GM GRID\")\n\np <- ggplot(data = my_varimpGM, aes(x = variable, y =scaled_importance ))\n\np <- p + geom_bar(stat = \"identity\")\np <- p + coord_flip()\np\n\n\n\nmodel = best_glm\n\n\npred2 = h2o.predict(object = model, newdata = teste.hex)\n\n\ndataset_pred <- as.data.frame(pred2)\n\n\nsub_reg <- data.frame(id_jogador = teste$id_jogador,  id_partida = teste$id_partida, temporada = teste$nome_temporada, posicao =  dataset_pred$predict)\n\n\nfinal <- cbind(dataset_pred, teste ) \nerro =  sqldf( \"select * from final where predict != posicao\")\n\nperf <- h2o.performance(model, teste.hex)\nh2o.confusionMatrix(perf)\n\n\n# Summary of the best model\nsummary(pred2, exact_quantiles=TRUE)\n\n\nreturn (mean(pred2$predict==teste.hex$posicao))\n\n}",
    "created" : 1498491137994.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2637009275",
    "id" : "910CC7F8",
    "lastKnownWriteTime" : 1498840352,
    "last_content_update" : 1498840352403,
    "path" : "~/Downloads/MDM/MDM Predict 5p/scripts/gridGM.R",
    "project_path" : "scripts/gridGM.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}